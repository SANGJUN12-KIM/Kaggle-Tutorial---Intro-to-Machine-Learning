{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Kaggle-Tutorial\n",
    "\n",
    "## Intro to Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "### 램덤 포레스트Random Forests\n",
    "\n",
    "더 정교한 머신러닝 알고리즘을 사용해보자\n",
    "\n",
    "원본: [Underfitting and Overfitting](https://www.kaggle.com/dansbecker/random-forests)\n",
    "\n",
    "---\n",
    "\n",
    "### 도입\n",
    "\n",
    "의사결정트리는 당신에게 어려운 결정을 남긴다. 많은 잎을 가지는 깊은 트리는 각 예측이 단지 적은 수의 집들이 포함된 잎에서 나온 역사적인 테이터로 부터 나오기 때문에 과적합될 수 있다. 그러나 잎이 거의 없는 얕은 트리 역시 raw data에서 많은 구별점을 포착하지 못하기에 성능이 좋지 않다.\n",
    "\n",
    "오늘 가장 정교한 모델리 기술들 역시 이러한 과소적합과 과대적합 사이의 긴장을 직면한다. 하지만, 많은 모델들른 현병한 아이디어롤 가지고 더 나은 성능을 이끌 수 있다. 우리는 그 예로 램덤포레스트를 볼 것이다.\n",
    "\n",
    "랜덤포레스트는 많은 트리들을 사용하여, 각 구성 요소 트리의 예측값에 대한 평균으로 예측을 수행한다. 일반적으로 단일 의사결정트리보다 훨씬 더 나은 예측 정확도를 가지며, 기본 매개변수들Parametaers과 함께 잘 동작한다. 만일 당신이 모델링을 이어가면서, 더 나은 성을을 가지는 다양한 모델들을 배울 수 있지만, 그 모델들은 많은 경우 올바를 매개변수parameter를 얻는데  주의를 요한다.\n",
    "\n",
    "\n",
    "### 예\n",
    "\n",
    "당신은 이미 데이러를 로드하는 코드를 몇번 고았다. 데이터의 로딩을 마치면, 우리에게는 다음과 같은 변수가 따라온다\n",
    "\n",
    "* train_X\n",
    "* val_X\n",
    "* train_y\n",
    "* val_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path)\n",
    "# Filter rows with missing values\n",
    "melbourne_data = melbourne_data.dropna(axis=0)\n",
    "# Choose target and features\n",
    "y = melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea',\n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time we\n",
    "# run this script.\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "우리는 Scikit-learn에서 의사결정 트리를 만든 방법과 유사한 랜덤 포레스트 모델을 구축한다.\n",
    "이번에는 `DecisionTreeRegressor` 대신  `RandomForestRegressor` 클래스를 사용한다.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "melb_preds = forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, melb_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> 191669.7536453626"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 결론\n",
    "추가적인 개선의 여지는 있겠지만, 이는 250,000개의 의사결정 트리에 비하면 큰 개선이다. 단일 의사결정트리의 최대 깊이를 변경한 것 처럼 랜덤포레스트의 성능을 크게 개선할 수 있는 매개변수parameter가 있다. 그러나, 랜덤포레스트의 가장 큰 특징중하나는 이러한 튜닝없이도 일반적으로 합리적인 결과로 동작한다는 것이다.다\n",
    "\n",
    "### 당신의 차례\n",
    "\n",
    "[랜덤포레스트를 이용](https://www.kaggle.com/sangjun12/exercise-random-forests/edit)하여 당신의 모델의 성능이 얼마나 향상되는지 확인."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}